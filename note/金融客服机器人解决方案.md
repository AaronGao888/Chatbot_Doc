# 金融客服机器人解决方案

* 题目：`基于短文本相似度的客服机器人设计`

### 前言

​      这个题目其实就是Natural Language Inference、Sentence Match这一类经典NLP问题，简单来说就是判断两个sentence的关系，在本比赛中，就是判断两个sentence是否语意一致。这个任务非常有实用价值，尤其是在构建一个客服系统的时候，能够让解决目前客服系统难以解决的2个问题：

* 如何使得客服机器人能理解用户输入意图？
* 如何使得回复的答案更符合逻辑？

关于如何解决了上面问题，会放在之后章节解答。在目前，一个好的客服系统，客服机器人不仅需要模仿人类的回复语气，而且回答的问题可能从爱因斯坦的相对论跑到最近某当红小花旦的恋爱新闻，亦或是帮你完成旅行安排等复杂任务。这些是目前对话算法研究的长远目标之一。AI，这个看似遥远的概念一直让人捉摸不透。然而从目前的学术研究界和行业的观察中，我们看到了希望。更多的人和机构投入AI研究，这一阶段产生了大量的可以用于客服机器人训练的语聊，再加上硬件水平的突破，让迁移学习(Transfer Learning))和强化学习（Reinforcement Learning）的算法可以得到工业应用。

​     本项目结合以往客服机器人遇到的难题，以及目前AI技术的突破进展，提出了一个基于迁移学习算法的客服系统，在赛题方给出的数据中达到了99.6%的准确率，在调研中，本项目是目前state-of-the-art的模型

#### 介绍

​      近几年，基于问答系统的智能助理备受关注。这一方面得益于以深度学习为代表的人工智能技术的发展，另一方面是源自于现实世界的需求。

​      客户服务是智能助理能大展身手的一个重要领域。随着互联网金融的迅速发展，社会对客服提出了强烈的需求。同时，用户也越来越注重金融产品的体验和服务的质量。传统客服所存在的问题愈发突出，例如，人工客服存在工作时间问题，由于服务能力不足而存在客户长时间等待，无法应对服务的突发增长等。

​    为解决这些问题，本项目，将人工客服从一些基本的、常见的和重复性的工作中解放出来，真正地聚焦于的确需要人工参与的客服交流中。小U机器人提供二种服务：客户服务和聊天服务。它可以接受语音和文本输入，集成了机器人问答场景，并可进行多轮交互。目前，它每日完成数百万次以中文为主的客户问答。本文将介绍小U机器人的底层实现技术。论文的主要贡献包括：

1. 小U实现了一种应用于真实商业场景中的智能助理，针对客户在金融证券分析中所遇到的问题提供客服服务和聊天服务。
2. 使用CNN模型判定客户意图。
3. 在客户服务中使用了基于语义规范化和知识图谱的方法，实现了面向知识的客户问答。
4. 在聊天服务中使用了一种混合了信息检索和迁移学习生成模型的方法，优化了两种模型的联合输出。

#### 系统结构

![1546409680346](.\img\系统架构.png)

​    小U机器人的项目架构如图1所示。在模型训练过程中，我们使用到了一台集成了4张:NVIDIA TitanXP显卡的Ubuntu服务器，因为数据量的原因，一般在半个小时内就能完成全部训练。数据库选择上面，我们使用SQLlite来存储倒排索引及标准问信息，用Neo.4j来完成知识图谱推理，使用Mysql来存储标准知识库，标准答案库和用户交互的日志情况；在数据库上层我们封装了很多算法，来完成数据交互的各个逻辑；通过算法加工好的数据会用于业务层应用。而前端则负责展示页面数据。



![1546409680346](.\img\系统流程.png)

​	图二是本项目的流程框图，当用户输入问题后，进入语法解析模块。语法解析模块会对数据进行一定的纠错，分词等处理然后再构成一颗句法依存树。知识库匹配模块便是将这颗树与内存中存放的所有标准问的句法依存匹配。如果输入的问题，在标准知识库中正好有这个问题，那么我们便可以直接通过索引从数据库中查到对应的答案，并将其返回给用户。另外输入数据还会并行进入一个实名体识别模块，通过知识图谱引擎检索对应的关联实体，提供用户候选的参考。举个例子：当你输入问题“恒生电子公司股票代码是什么？”，我们可以提取出恒生电子这个公司实体，并通过Neo.4j的检索，我们便能在页面上展示与“恒生电子”公司最近新闻，股票走势，或者公司资质等信息，为用户提供更多的人性化参考。在标准库不匹配的情况下，输入语句会进入一个卷积神经网络（Convolutional Neural Networks，CNN）构建的分类器用于用户的意图识别，如果识别为闲聊类，则会进入一个seq2seq+attention的闲聊机器人模块，我们最终将改模块计算的结果返回给用户。另外，如果判断为咨询类的话，那么意味着我们标准知识库中有大概率能找到答案，这时，我们将输入数据与标准库全部数据做一个全文检索，这部分我们用到了大名鼎鼎的BM25算法。BM25算法会为我们的输入信息与每个标准知识库的信息计算一个相似度分值，再排序后我们取靠前的一小部分数据来进行最后的`相似度`判断。依赖于BM25算法的高效性，我们可以在后续的`相似度算法`上增加更多的参数与构想来使得其准确率能高。举个例子：输入“A股开户是否收费”的时候。我们使用BM25算法从10万条标准问的数据库中挑选出200条存在`A股`、`开户`等关键信息的标准问，道理其实显而易见，我们不需在于输入毫无联系的标准问上浪费很多的计算量。这样真正参与计算相似度的就是`输入信息`与这`200条的标准问`信息。在这个相似度判断的核心模块中，我们突破性的引入迁移学习+BERT算法，在赛题方给出的数据中达到了99.6%的准确率，迁移学习提供的大量词向量，使得项目训练模型泛化能力很强，但是参数过多也导致预测效率不高的问题。因此，本项目也提出第二个解决方案，使用孪生网络Bilistm部署的相似度算法，在保证的一定的准确率的情况下，也大大的提升了运行效率。通过深度学习的相似度判断模型，我们输入信息与这小批量的数据又诞生了一轮相似度度量值，通过这个值来重排序。对于TOP1高于90%的标准问，我们直接将其作为用户想咨询的问题，然后从答案库内检索对应答案返回用户。对于TOP1低于0.5的数据，我们直接回复“不清楚您的问题”，来让用户调整输入。对于处于其中的一些我们取TOP5返回给用户，对应形式为“请问你想问的问题是下面几个吗？”

#### 语法解析模块：

- 这过程我们主要依赖于Python的第三方解析库[Hanlp](http://hanlp.linrunsoft.com/)来实现，Hanlp中文自然语言处理中的分词方法有标准分词、NLP分词、索引分词、N-最短路径分词、CRF分词以及极速词典分词等。在分词的过程中我们使用其极速度词典分词模式。而对于分词所需要的词典，本文使用了腾讯开源的800万条中文词典和词向量资源。

​       数据开源信息：[腾讯AI Lab开源大规模高质量中文词向量数据，800万中文词随你用](https://cloud.tencent.com/developer/article/1356164)

​       数据官方下载地址：[Tencent AI Lab Embedding Corpus for Chinese Words and Phrases](https://ai.tencent.com/ailab/nlp/embedding.html)

​       小量数据下载地址：[腾讯word2vec模型缩小版](https://github.com/cliuxinxin/TX-WORD2VEC-SMALL)     			                                                引用`[1]`-`[10]`

- 另外Hanlp还基于最大熵模型和最大生成树模型，实现了中文依存句法的自动分析，在封闭测试集（取自训练集）上取得了99.20%的准确率（UA），分析速度达到 570.7句/秒。我们将其放入我们的项目中实现对用户输入的快速语法分析，构建句法树。

  ![1546401324839](.\img\Hanlp.png)

​        Jieba和Hanlp的高效性能，给整个客服机器人模块打定了很好的基础，因为后续的算法层面往往涉及到大量的矩阵运算，如果前面模块的计算量耗时大的话，会让整个项目显得迟缓臃肿。这里再解释一下，我们先使用jieba对一个短语进行分词然后语法分析形成了句法依存树，这个过程我们可以得到我们需要的2个内容：1，命名实体。类如：地名，人名，公司名等实体，在句法依存的分析中可以得到。2构建了一个句法依存树，这颗树的目的是为了如果客户问题就等于标准库问题时可以快速的在模板库中找到对应的标准问。这就类如一个二叉树查询过程，可以再上亿条数据中实现MS级别的反应。

  可以查看：[Hanlp在线demo](http://hanlp.com/)来了解Hanlp的具体功能。

参考文档：

[阿里小蜜：提供创新电子商务体验的智能助理](https://www.zybuluo.com/Rays/note/1024203)

[基于神经网络的智能对话系统（一）——介绍](https://blog.csdn.net/u011239443/article/details/84565629)

#### 标准知识库匹配模块：

​      正如上面提到的，我们构建了一个句法依存树，我们把句法依存树的理解为Trie树的一种变体，只是在这个过程中构建一个句法依存树，可以方便我们的`命名实体识别`。实际在标准知识库的匹配过程是与Trie树查询无异的，所以这个模块的介绍，实则是一个Trie树的解析查询过程。

相关介绍：[海量数据处理之Tire树（字典树）](https://blog.csdn.net/ts173383201/article/details/7858598)

​     当我们用户输入与标准问，通过trie树快速匹配到后，我们就可以直接从数据库中输出标准问的答案了。当为匹配到的标准知识库问题时候，我们将进入一个意图识别模块。

#### 意图识别模块：

​    意图识别模块，我们基于CNN设计一个字符级的短文本分类器，这是一个二分类的任务，用于判断用户输入信息的内容，如果判断为闲聊类，则直接进入一个seq2seq+attention的闲聊机器人模块，如有判断为咨询类，那我们将进入一个基于BM25算法的全文检索模块。

#### BM25的全文检索模块：

​     BM25的全文检索模块，实则是一个数据筛选的过程，类如我们输入：A股停牌了吗？，通过sticSearch的全文检索模块的筛选，我们不用去与数据库存储的假设10万条标准问去计算相似度，而是去与标准知识库中有'A股'，或者'停牌'这样关键字的少量标准问去计算短文本相似度。

​    使用到的倒排索引以及BM25等算法，可以在得到一个输入时，快速响应，这个过程也是MS级别的，时间利用率特别高。

#### 短文本相似度模块：

​	这是项目的核心内容，在项目我们设计了2个解决方案，这2个方案我们都取得了很好的成绩（`方案1` 99.6%的准确率 99.4%的F1。`方案2`99.3%的准确率 99.3%的F1。）

- 解决方案1：具有良好的泛化能力，可以但不限于用于金融知识领域，可以扩充到任何知识领域，并且在之后知识库扩充的过程中，不用再重新训练一次算法模型。但缺点在于具有上亿个神经网络参数，运行响应速度慢。

- 解决方案2：具有很快的响应能力，可以在用户输入后快速回复。但缺少一定的泛化能力，当知识库的问题库扩充之后，往往需要再次训练一次模型。这样部署上线往往需要定时的更新跑动算法模型。

  关于涉及到的算法模型和技术文档，这些草稿部分可以由我和付同学承担，之后文档同学整理这个过程，和项目整体文档风格统一即可。

#### 相似度阈值判断

​	这个是由赛题方要求的，不做多的解释。 当单条相似度高于0.8，就直接返回最高相似度的这条。当top1处于0.6-0.8之间，返回处于0.8-0.6的所有标准问：例子 请问你想问的是：1.A股是否停牌？ 2. A股的行情如何？ 当低于0.5时，直接返回不知道。

#### 知识图谱辅助：

​	本项目设计了一个知识图谱辅助预测，在命名实体识别中如果实体存在于知识图谱，那么会将图谱的关系内容返回到界面中展示，这样可以提供更多的参考信息。更为人性化。



#### 引用：

Li F L , Qiu M , Chen H , et al. AliMe Assist: An Intelligent Assistant for Creating an Innovative E-commerce Experience[J]. 2018.

[1] Tomas Mikolov, Ilya Sutskever, Kai Chen, Gregory S. Corrado, and Jeffrey Dean:Distributed Representations of Words and Phrases and their Compositionality. NIPS 2013.

[2] Jeffrey Pennington, Richard Socher, and Christopher D. Manning. GloVe: Global Vectors for Word Representation. EMNLP 2014.

[3] P. Bojanowski, E. Grave, A. Joulin, T. Mikolov, Enriching Word Vectors with Subword Information. TACL 2017 (5).

[4] Shen Li, Zhe Zhao, Renfen Hu, Wensi Li, Tao Liu, Xiaoyong Du. Analogical Reasoning on Chinese Morphological and Semantic Relations. ACL 2018.

[5] Shuming Shi, Huibin Zhang, Xiaojie Yuan, and Ji-Rong Wen. Corpus-based Semantic Class Mining: Distributional vs. Pattern-Based Approaches. COLING 2010.

[6] Yan Song, Shuming Shi, Jing Li, and Haisong Zhang. Directional Skip-Gram: Explicitly Distinguishing Left and Right Context for Word Embeddings. NAACL 2018.

[7] Jialong Han, Yan Song, Wayne Xin Zhao, Shuming Shi, and Haisong Zhang. hyperdoc2vec: Distributed Representations of Hypertext Documents. ACL 2018.

[8] Jichuan Zeng, Jing Li, Yan Song, Cuiyun Gao, Michael R. Lyu, and Irwin King. Topic Memory Networks for Short Text Classification. EMNLP 2018.

[9] Yan Song and Shuming Shi. Complementary Learning of Word Embeddings. IJCAI 2018.

[10] Yan Song, Shuming Shi, and Jing Li. Joint Learning Embeddings for Chinese Words and their Components via Ladder Structured Networks. IJCAI 2018.